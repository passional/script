import streamlit as st
from utils.api_utils import call_openai_api, get_prompt_content
from utils.config_loader import get_prompts # To load all prompts once

# Page Configuration
st.set_page_config(page_title="å¤§çº²ç”Ÿæˆ", layout="wide", initial_sidebar_state="expanded")
st.sidebar.header("å¤§çº²ç”Ÿæˆ") # Optional: Add a header to the sidebar for this page

# Load all prompts once
PROMPTS_CONFIG = get_prompts()

def check_api_config():
    """Checks if API is configured and displays a message if not."""
    if "api_config" not in st.session_state or not st.session_state.api_config.get("configured", False):
        st.warning("API å°šæœªé…ç½®ã€‚è¯·å…ˆå‰å¾€ ğŸ”‘ API é…ç½®é¡µé¢è¿›è¡Œè®¾ç½®ã€‚")
        st.page_link("pages/00_API_Configuration.py", label="å‰å¾€ API é…ç½®", icon="ğŸ”‘")
        return False
    return True

def outline_generation_page():
    st.title("æ­¥éª¤ 1: ğŸ“ å¤§çº²ç”Ÿæˆ")
    st.markdown("è¯·è¾“å…¥æ‚¨çš„è§†é¢‘ä¸»é¢˜ï¼ŒAI å°†ä¸ºæ‚¨ç”Ÿæˆåˆæ­¥çš„è§†é¢‘å¤§çº²ã€‚")

    if not check_api_config():
        st.stop() # Stop execution if API is not configured

    # Initialize session state variables for this page if they don't exist
    if "topic_input" not in st.session_state:
        st.session_state.topic_input = ""
    if "outline_content" not in st.session_state:
        st.session_state.outline_content = ""
    if "outline_score_feedback" not in st.session_state:
        st.session_state.outline_score_feedback = ""
    if "last_outline_request" not in st.session_state: # For "View AI Request"
        st.session_state.last_outline_request = {}
    if "last_score_request" not in st.session_state: # For "View AI Request"
        st.session_state.last_score_request = {}


    # --- UI Elements ---
    st.session_state.topic_input = st.text_area(
        "è¯·è¾“å…¥è§†é¢‘ä¸»é¢˜:", 
        value=st.session_state.topic_input,
        height=100,
        placeholder="ä¾‹å¦‚ï¼šå¦‚ä½•ç”¨ Streamlit åˆ¶ä½œä¸€ä¸ªç®€å•çš„ Web åº”ç”¨"
    )

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸš€ ç”Ÿæˆå¤§çº²", type="primary", use_container_width=True):
            if not st.session_state.topic_input.strip():
                st.warning("è¯·è¾“å…¥è§†é¢‘ä¸»é¢˜ã€‚")
            else:
                with st.spinner("AI æ­£åœ¨ç”Ÿæˆå¤§çº²ä¸­ï¼Œè¯·ç¨å€™..."):
                    api_conf = st.session_state.api_config
                    system_msg, user_msg_text_template, params = get_prompt_content( # Renamed user_msg_template to user_msg_text_template for clarity
                        "outline_generation", 
                        api_conf["selected_model"], 
                        PROMPTS_CONFIG,
                        {"topic": st.session_state.topic_input}
                    )
                    st.session_state.last_outline_request = {"system": system_msg, "user": user_msg_text_template, "params": params}

                    if user_msg_text_template is not None: # Check if prompt text was successfully prepared
                        generated_outline = call_openai_api(
                            api_key=api_conf["api_key"],
                            base_url=api_conf["base_url"],
                            model=api_conf["selected_model"],
                            system_message=system_msg,
                            user_message_text=user_msg_text_template, # Changed from user_message
                            temperature=params.get("temperature", 0.7), 
                            max_tokens=params.get("max_tokens", 1500)
                        )
                        if generated_outline:
                            st.session_state.outline_content = generated_outline
                            st.session_state.outline_score_feedback = "" # Clear previous score
                        else:
                            st.error("æœªèƒ½ç”Ÿæˆå¤§çº²ã€‚è¯·æ£€æŸ¥ API é…ç½®æˆ–ç¨åå†è¯•ã€‚")
                    else:
                        st.error("æœªèƒ½å‡†å¤‡ç”Ÿæˆå¤§çº²çš„æç¤ºè¯ã€‚")


    st.divider()
    st.subheader("AI ç”Ÿæˆçš„å¤§çº²")
    st.session_state.outline_content = st.text_area(
        "é¢„è§ˆå’Œç¼–è¾‘å¤§çº²:", 
        value=st.session_state.outline_content, 
        height=300,
        key="outline_edit_area"
    )

    if st.session_state.outline_content:
        if st.button("ğŸ§ AI è¯„åˆ†å¤§çº²", use_container_width=True):
            with st.spinner("AI æ­£åœ¨å¯¹å¤§çº²è¿›è¡Œè¯„åˆ†ï¼Œè¯·ç¨å€™..."):
                api_conf = st.session_state.api_config
                system_msg, user_msg_text_template, params = get_prompt_content( # Renamed for clarity
                    "outline_scoring",
                    api_conf["selected_model"],
                    PROMPTS_CONFIG,
                    {"outline_content": st.session_state.outline_content}
                )
                st.session_state.last_score_request = {"system": system_msg, "user": user_msg_text_template, "params": params}

                if user_msg_text_template is not None: # Check if prompt text was successfully prepared
                    score_feedback = call_openai_api(
                        api_key=api_conf["api_key"],
                        base_url=api_conf["base_url"],
                        model=api_conf["selected_model"], 
                        system_message=system_msg,
                        user_message_text=user_msg_text_template, # Changed from user_message
                        temperature=params.get("temperature", 0.5),
                        max_tokens=params.get("max_tokens", 1000)
                    )
                    if score_feedback:
                        st.session_state.outline_score_feedback = score_feedback
                    else:
                        st.error("æœªèƒ½è·å–å¤§çº²è¯„åˆ†ã€‚")
                else:
                    st.error("æœªèƒ½å‡†å¤‡è¯„åˆ†å¤§çº²çš„æç¤ºè¯ã€‚")


    if st.session_state.outline_score_feedback:
        st.subheader("AI è¯„åˆ†åé¦ˆ")
        st.markdown(st.session_state.outline_score_feedback)

    # --- Optional: View AI Request ---
    with st.expander("ğŸ” æŸ¥çœ‹ä¸Šä¸€æ¬¡ AI è¯·æ±‚å†…å®¹ (ä»…ä¾›è°ƒè¯•)", expanded=False):
        if st.session_state.last_outline_request.get("user"):
            st.markdown("**ä¸Šæ¬¡ç”Ÿæˆå¤§çº²è¯·æ±‚:**")
            st.json(st.session_state.last_outline_request)
        if st.session_state.last_score_request.get("user"):
            st.markdown("**ä¸Šæ¬¡è¯„åˆ†å¤§çº²è¯·æ±‚:**")
            st.json(st.session_state.last_score_request)
            
    # --- Navigation or next step ---
    if st.session_state.outline_content:
        st.divider()
        if st.button("âœ… ç¡®è®¤å¤§çº²å¹¶å‰å¾€å£æ’­ç¨¿ç”Ÿæˆ", type="primary"):
            st.success("å¤§çº²å·²ç¡®è®¤ï¼è¯·ä»å·¦ä¾§å¯¼èˆªæ é€‰æ‹©â€œå£æ’­ç¨¿ç”Ÿæˆâ€ã€‚")
            st.page_link("pages/02_ğŸ—£ï¸_å£æ’­ç¨¿ç”Ÿæˆ.py", label="å‰å¾€å£æ’­ç¨¿ç”Ÿæˆ", icon="ğŸ—£ï¸")


if __name__ == "__main__":
    outline_generation_page()